--
title: "Untitled"
author: "vidhu"
date: "June 15, 2018"
output: html_document
---
```{r}

levels(Adult_dummy_del$income) =      make.names(levels(factor(Adult_dummy_del$income)))

```
# Control for smote modelling
```{r}
set.seed(400)
ctrl = trainControl(method = "cv", 
                     number = 5, 
                     sampling = "smote",
                     summaryFunction= twoClassSummary, 
                     classProbs=T,
                     savePredictions = T)
```
# kNN -smote
```{r}
grid = expand.grid(k=c(19,31,41,51,101, 125,151, 201))
knnFit = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "knn", use.all = T,trControl = ctrl, metric = "ROC", tuneGrid = grid)
```

```{r}
plot(knnFit)
varImp(knnFit)
plot(varImp(knnFit), main = "variable importance knn")
```

# Random Forest- smote
```{r}
rfFit = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "rf", trControl = ctrl, metric = "ROC", tuneLength = 5)

```

```{r}
grid = expand.grid(.mtry =2)
rfFit_tuned = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "rf", trControl = ctrl, metric = "ROC",ntree =100, tuneGrid = grid)

```

Result of above chunk

Random Forest 

45175 samples
   20 predictor
    2 classes: 'X0', 'X1' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 36140, 36140, 36140, 36140, 36140 
Addtional sampling using SMOTE

Resampling results:

  ROC        Sens       Spec    
  0.8819329  0.7902161  0.806107

Tuning parameter 'mtry' was held constant at a value of 2
--------
Even ran the rf for ntree = 300 and 1000. 
for 300, the roc was lower and for 1000, it was not able to fit the model. So the tunned model will have ntree = 500 and mtry = 2
--------
```{r}
# Final model 
rfFit
plot(rfFit)
#look at the variable importance and ploting
varImp(rfFit)
plot(varImp(rfFit), main = "variable importance random forests")

```
# Support vector Machine model
```{r}

svm_linearFit = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "svmLinear", trControl = ctrl, metric = "ROC", tuneLength = 20)

```


```{r}
grid <- expand.grid(C = c(0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2,5))
svm_linearFit_tuned = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "svmLinear", trControl = ctrl, metric = "ROC", tuneGrid = grid)

```

```{r}

svm_RadialFit = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "svmRadial", trControl = ctrl, metric = "ROC", tuneLength = 10)

```



# Gradient boosting Smote

```{r}

gbmFit = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "gbm", trControl = ctrl, metric = "ROC", tuneLength = 10)

```

#Logistic Regression - smote
```{r}
glmFit = train(Adult_dummy_del[,P1], Adult_dummy_del[,"income"], method = "glm", trControl = ctrl, metric = "ROC", family="binomial")

```

NoW all models with all 37 features
```{r}
grid = expand.grid(k=c(19,31,41,51,101, 125,151, 201))
KNNFit = train(Adult_dummy_del[,results$optVariables], Adult_dummy_del[,"income"], method = "knn", use.all = T,trControl = ctrl, metric = "ROC", tuneGrid = grid)
```

```{r}
RFFit = train(Adult_dummy_del[,results$optVariables], Adult_dummy_del[,"income"], method = "rf", trControl = ctrl, metric = "ROC", tuneLength = 5)

```

```{r}

SVM_linearFit = train(Adult_dummy_del[,results$optVariables], Adult_dummy_del[,"income"], method = "svmLinear", trControl = ctrl, metric = "ROC", tuneLength = 20)

```


```{r}

GBMFit = train(Adult_dummy_del[,results$optVariables], Adult_dummy_del[,"income"], method = "gbm", trControl = ctrl, metric = "ROC", tuneLength = 10)

```


```{r}
GLMFit = train(Adult_dummy_del[,results$optVariables], Adult_dummy_del[,"income"], method = "glm", trControl = ctrl, metric = "ROC", family="binomial")
#comparison with glmFit
anova(GLMFit$finalModel, test = "LRT")
#some variables are  less significant.
```


After removing less significant variables.
```{r}
lessPvalues = results$optVariables[c(1:24,26:28,30:31,33:37)]
GLM1Fit = train(Adult_dummy_del[,lessPvalues], Adult_dummy_del[,"income"], method = "glm", trControl = ctrl, metric = "ROC", family="binomial")
# Now all variables are significant. we will compare this model with the glmFit.

```


```{r}

Adult_del = Adult_dummy[which(complete.cases(Adult_dummy)==TRUE),]
colnames(Adult_del)[colnames(Adult_del)=="income..50K"] = "income"
levels(Adult_del$income) =      make.names(levels(factor(Adult_del$income)))


glmFitwithall = train(income~.,Adult_del, method = "glm", trControl = ctrl, metric = "ROC", family="binomial")

```

```{r}
# predictions
temp_knn = knnFit$pred[knnFit$pred$k==101,]
predictions_knn = temp_knn$pred[order(temp_knn$rowIndex)]
temp_rf = rfFit$pred[rfFit$pred$mtry==2,]
predictions_rf = temp_rf$pred[order(temp_rf$rowIndex)]
temp_svm = svm_linearFit_tuned$pred[svm_linearFit_tuned$pred$C==0.25,]
predictions_svm = temp_svm$pred[order(temp_svm$rowIndex)]
temp_gbm = gbmFit$pred[which(gbmFit$pred$interaction.depth==10 & gbmFit$pred$n.trees==100 & gbmFit$pred$shrinkage==0.1& gbmFit$pred$n.minobsinnode == 10),]
predictions_gbm = temp_gbm$pred[order(temp_gbm$rowIndex)]
predictions_glm = glmFit$pred$pred[order(glmFit$pred$rowIndex)]
predictions_GLM = GLMFit$pred$pred[order(GLMFit$pred$rowIndex)]
predictions_GLM1 = GLM1Fit$pred$pred[order(GLM1Fit$pred$rowIndex)]
predictions_glmwithall = glmFitwithall$pred$pred[order(glmFitwithall$pred$rowIndex)]




#Confusion Matrix
cm_knn = confusionMatrix(predictions_knn,Adult_dummy_del[,"income"])
cm_rf = confusionMatrix(predictions_rf,Adult_dummy_del[,"income"])
cm_gbm = confusionMatrix(predictions_gbm,Adult_dummy_del[,"income"])
cm_svm = confusionMatrix(predictions_svm,Adult_dummy_del[,"income"])
cm_glm = confusionMatrix(predictions_glm,Adult_dummy_del[,"income"])
cm_GLM = confusionMatrix(predictions_GLM,Adult_dummy_del[,"income"])
cm_GLM1 = confusionMatrix(predictions_GLM1,Adult_dummy_del[,"income"])
cm_glmwithall = confusionMatrix(predictions_glmwithall,Adult_dummy_del[,"income"])
```
By looking at the confusion matrices we see that GLM model gives  better accuracy. 
Also
k <- length(glmFit$finalModel$coefficients)
D_M <- glmFit$finalModel$deviance
D_0 <- glmFit$finalModel$null.deviance

1 - pchisq(q = D_0 - D_M, df = k - 1)
gives 0, therefore we reject the null hypothesis that there is no significant difference between the grand mean model (intercept-only model) and the model "glm.model.wld" (model with predictors). This means that at the 5% significance level the null model does not fit the observed data better than the multivariate model "glm.model.wld".
```{r}
# Plotting ROC
library(pROC)
plot.roc(knnFit$pred$obs[knnFit$pred$k == 101],knnFit$pred$X0[knnFit$pred$k == 101], col = "blue")

plot.roc(rfFit$pred$obs[rfFit$pred$mtry == 2],rfFit$pred$X0[rfFit$pred$mtry == 2], add= T, col = "black")

plot.roc(gbmFit$pred$obs[gbmFit$pred$interaction.depth==10 & gbmFit$pred$n.trees==100 & gbmFit$pred$shrinkage==0.1& gbmFit$pred$n.minobsinnode == 10],gbmFit$pred$X0[gbmFit$pred$interaction.depth==10 & gbmFit$pred$n.trees==100 & gbmFit$pred$shrinkage==0.1& gbmFit$pred$n.minobsinnode == 10], add = T, col = "red")

```
# Run all models with imputing missing values.
```{r}
Adult_dummy_imputed = knnImputation(Adult_dummy)
colnames(Adult_dummy_imputed)[colnames(Adult_dummy_imputed)=="income..50K"] = "income"
levels(Adult_dummy_imputed$income) =      make.names(levels(factor(Adult_dummy_imputed$income)))
```

```{r}
grid = expand.grid(k=c(19,31,41,51,101, 125,151, 201))
knnFit_imputed = train(Adult_dummy_imputed[,P1], Adult_dummy_imputed[,"income"], method = "knn", use.all = T,trControl = ctrl, metric = "ROC", tuneGrid = grid)
```



```{r}
rfFit_imputed = train(Adult_dummy_imputed[,P1], Adult_dummy_imputed[,"income"], method = "rf", trControl = Ctrl, metric = "ROC", tuneLength = 10)

```
Since imputation is not improving the result, therefore continuing with the deleted missing values.




# Comparing models
```{r}
resamps= resamples(list(rf = rfFit, knn =KNNFit,svm = svm_linearFit_tuned, glm = glmFit, gbm = gbmFit))
theme1 <- trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .2, .2, .4)
theme1$plot.symbol$pch = 16
theme1$plot.line$col = rgb(1, 0, 0, .7)
theme1$plot.line$lwd <- 2
trellis.par.set(theme1)
bwplot(resamps, layout = c(3, 1))
difValues <- diff(resamps)
summary(difValues)
```
All the p values are greater than 0.05, so there is no much difference between the models in terms of roc.
```{r}
#Table for comparison
col1=c(cm_knn$byClass["Balanced Accuracy"],cm_rf$byClass["Balanced Accuracy"], cm_svm$byClass["Balanced Accuracy"], cm_gbm$byClass["Balanced Accuracy"], cm_glm$byClass["Balanced Accuracy"])
col2=c(cm_knn$byClass["F1"],cm_rf$byClass["F1"], cm_svm$byClass["F1"], cm_gbm$byClass["F1"], cm_glm$byClass["F1"])
col3=c(cm_knn$overall["Accuracy"],cm_rf$overall["Accuracy"], cm_svm$overall["Accuracy"], cm_gbm$overall["Accuracy"], cm_glm$overall["Accuracy"])
table = data.frame(BalancedAccuracy = col1, Fmeasure = col2, Accuracy = col3)
rownames(table) = c("kNN", "Random Forests", "Support vector Machine", "Gradient Boost", "Regression")
```

```{r}
#Predictors for top layer models 
top_models = data.frame(predictions_knn,predictions_rf, predictions_gbm, predictions_glm) 

#GBM as top layer model 
ensemble_gbm = train(top_models,Adult_dummy_del[,"income"],method='gbm',trControl= ctrl,tuneLength=3)
```